# ML-welding-prediction

Даже пожалел что взялся за такой относительно простой в плане данных кейз.
Но за пару недель до сдачи уже было поздно менять(

Данных мало и на лекциях рассказывали что для нейросетей желательно иметь в районе десятков тысяч наблюдений.
Но всё-равно попробовал. Решил остановиться на одном полносвязном слое и поэкспериментировать с разным кол-м нейронов(10-100) и эпох обучения(10-100) для выбора лучшей конфигурации.
Произвёл 3 замера, в каждом пробовал предсказывать вместе Width и Depth и по-отдельности каждый.
В качестве метрики оценки качества выбрал mean_absolute_percentage_error, как отностельно простой для понимания показатель, который удобно сравнивать для нескольких предсказываемых величин.

Есть графики для лучих конфигураций(кол-во нейронов vs тестовая оценка) правда не совсем понятно что такое лучшая средняя оценка. Но судя по всему чем она выше тем лучше. Не получилось найти среди параметров то что было указано в losses при создании регрессора и в scoring при настройке сетки.

Итоговые результаты выписаны в эксельке, так же в папке misc есть полные логи, если интересно посмотреть поподробней на результаты.
Если бы данных было больше то можно было бы попробовать разные конфигурации слоёв и поперебирать доп параметры. Но на выборке из 72 это с большой вероятностью приведёт к переобучению, так что решил не пробовать.

Корреляция между некоторыми признаками довольно большая, но как говорили на консультации решил не убирать их из расчёта, да и судя по комментам на Хабре мультиколлинеарность следует подозревать в районе 0.9.

В приложении в качестве модели будем использовать лучшие из не нейросетевых алгоритмов
Как видим по эксельке это:
Depth — GradientBoostingRegressor
Width — DecisionTreeRegressor.

Модели перед выкаткой обучим на всём наборе данных, ибо данных итак мало, а так хоть на потенциальных новых данных точность может быть получше.
